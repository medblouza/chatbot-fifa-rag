ğŸ† FIFA Rules AI Chatbot
Description

FIFA Rules AI Chatbot est une application NLP basÃ©e sur une architecture moderne permettant de poser des questions en langage naturel sur les Lois du Jeu FIFA (saison 2024â€“2025).

Le projet implÃ©mente un chatbot spÃ©cialisÃ© utilisant :

une API REST FastAPI

une recherche sÃ©mantique (RAG) avec ChromaDB

un LLM local exÃ©cutÃ© via Ollama

une interface utilisateur interactive dÃ©veloppÃ©e avec Streamlit

Ce projet vise Ã  dÃ©montrer une expertise pratique en NLP appliquÃ©, architecture backend moderne et intÃ©gration de modÃ¨les de langage.

Objectifs du projet

Construire une API NLP performante avec FastAPI

ImplÃ©menter un chatbot RAG (Retrieval-Augmented Generation)

Exploiter des embeddings sÃ©mantiques pour la recherche de contexte

IntÃ©grer un LLM local pour la gÃ©nÃ©ration de rÃ©ponses

Fournir une interface utilisateur simple et interactive

PrÃ©parer le projet pour une future extension MLOps / Docker / SÃ©curitÃ©

FonctionnalitÃ©s actuelles

Questions en langage naturel sur les rÃ¨gles FIFA
Recherche vectorielle avec ChromaDB
GÃ©nÃ©ration de rÃ©ponses avec Ollama (LLM local)
API REST documentÃ©e automatiquement (Swagger)
Interface Streamlit pour interagir avec le chatbot
Sources retournÃ©es avec chaque rÃ©ponse

Architecture du projet
projetChatbot/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # API FastAPI
â”‚   â”œâ”€â”€ auth.py              # (PrÃ©parÃ© pour JWT - non activÃ©)
â”‚   â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py               # Interface Streamlit
â”‚
â”œâ”€â”€ vectors/
â”‚   â””â”€â”€ chroma_db/            # Base vectorielle persistÃ©e
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fifa_rules.txt
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_vectors.py      # GÃ©nÃ©ration des embeddings
â”‚
â””â”€â”€ README.md

Technologies utilisÃ©es
Backend

Python 3.10+

FastAPI

Uvicorn

Pydantic

ChromaDB

Ollama

NLP / IA

LLM local (LLaMA / Mistral via Ollama)

Embeddings Sentence Transformers

Architecture RAG

Frontend

Streamlit

Installation et exÃ©cution
1-PrÃ©requis

Python 3.10+

Ollama installÃ©

ModÃ¨le tÃ©lÃ©chargÃ© :

ollama pull llama3.2

2-Installation Backend
cd backend
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt


Lancer lâ€™API :

uvicorn main:app --reload


Swagger :

http://localhost:8000/docs

3-Lancer le Frontend
cd frontend
streamlit run app.py

Exemple de questions

Quelle est la durÃ©e dâ€™un match de football ?

Quand un carton rouge est-il attribuÃ© ?

Quelle est la rÃ¨gle du hors-jeu ?

Combien de joueurs peuvent Ãªtre remplacÃ©s ?

Quelles sont les sanctions pour une main volontaire ?


AmÃ©liorations futures

Authentification JWT

DÃ©ploiement Docker / Docker Compose

Cache Redis pour accÃ©lÃ©rer les rÃ©ponses

Monitoring et logs structurÃ©s

Frontend React

Tests unitaires et intÃ©gration

DÃ©ploiement cloud (AWS / GCP)